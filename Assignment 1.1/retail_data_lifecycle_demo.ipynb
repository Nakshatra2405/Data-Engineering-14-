{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63f86047",
   "metadata": {},
   "source": [
    "# Retail Data Lifecycle Mini Project\n",
    "This notebook demonstrates an **end-to-end data lifecycle** using synthetic retail data.\n",
    "\n",
    "Steps covered:\n",
    "1. Capture (generate synthetic data)\n",
    "2. Ingest (bronze layer)\n",
    "3. Transform (silver layer)\n",
    "4. Aggregate (gold layer)\n",
    "5. Modeling (demand forecasting)\n",
    "6. Forecasting next 7 days\n",
    "7. Visualization\n",
    "\n",
    "Outputs (`CSV` + `PNG`) can be imported into **Power BI** or any modern BI platform."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a0cec4",
   "metadata": {},
   "source": [
    "## 1. Setup & Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced1e70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_percentage_error, mean_squared_error\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create directories\n",
    "base = Path(\"retail_miniproject\")\n",
    "raw_dir = base / \"raw\"\n",
    "bronze_dir = base / \"bronze\"\n",
    "silver_dir = base / \"silver\"\n",
    "gold_dir = base / \"gold\"\n",
    "for d in [raw_dir, bronze_dir, silver_dir, gold_dir]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189a655a",
   "metadata": {},
   "source": [
    "## 2. Capture (Synthetic Data Generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451549ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.random.seed(42)\n",
    "start_date = datetime(2024, 1, 1)\n",
    "days = 365\n",
    "dates = [start_date + timedelta(days=i) for i in range(days)]\n",
    "stores = [\"store_A\", \"store_B\"]\n",
    "skus = [f\"sku_{i}\" for i in range(1,6)]\n",
    "\n",
    "sales_rows, inventory_rows, customers, promo_rows = [], [], [], []\n",
    "\n",
    "for date in dates:\n",
    "    is_weekend = date.weekday() >= 5\n",
    "    holiday_flag = 1 if (date.month == 1 and date.day == 26) or (date.month==12 and date.day in (25,26)) else 0\n",
    "    for store in stores:\n",
    "        for sku in skus:\n",
    "            base = 20 + (hash(sku) % 10)\n",
    "            seasonal = 5 * np.sin(2 * np.pi * (date.timetuple().tm_yday) / 365)\n",
    "            noise = np.random.poisson(3)\n",
    "            promo = np.random.binomial(1, 0.05)\n",
    "            qty = max(0, int(base + seasonal - (5 if not promo else -3) + (5 if is_weekend else 0) + noise + (-8 if holiday_flag else 0)))\n",
    "            price = round(100 + (hash(sku) % 30) - (5 if promo else 0), 2)\n",
    "            sales_rows.append([date.strftime(\"%Y-%m-%d\"), store, sku, qty, price, int(promo)])\n",
    "            on_hand = max(0, 200 - np.random.randint(0,50) - qty)\n",
    "            inventory_rows.append([date.strftime(\"%Y-%m-%d\"), store, sku, on_hand])\n",
    "    if np.random.rand() < 0.2:\n",
    "        customers.append([f\"cust_{np.random.randint(1,5000)}\", date.strftime(\"%Y-%m-%d\")])\n",
    "\n",
    "promo_rows = [\n",
    "    [\"P1\",\"sku_1\",\"2024-02-01\",\"2024-02-10\",10],\n",
    "    [\"P2\",\"sku_3\",\"2024-11-20\",\"2024-11-30\",15],\n",
    "]\n",
    "\n",
    "sales_df = pd.DataFrame(sales_rows, columns=[\"date\",\"store_id\",\"sku\",\"qty\",\"unit_price\",\"promo\"])\n",
    "inventory_df = pd.DataFrame(inventory_rows, columns=[\"snapshot_date\",\"store_id\",\"sku\",\"on_hand\"])\n",
    "customers_df = pd.DataFrame(customers, columns=[\"customer_id\",\"signup_date\"]).drop_duplicates(\"customer_id\")\n",
    "promo_df = pd.DataFrame(promo_rows, columns=[\"promo_id\",\"sku\",\"start_date\",\"end_date\",\"discount_pct\"])\n",
    "\n",
    "# Save raw\n",
    "sales_df.to_csv(raw_dir/\"sales_raw.csv\", index=False)\n",
    "inventory_df.to_csv(raw_dir/\"inventory_raw.csv\", index=False)\n",
    "customers_df.to_csv(raw_dir/\"customers.csv\", index=False)\n",
    "promo_df.to_csv(raw_dir/\"promotions.csv\", index=False)\n",
    "\n",
    "sales_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a488e2",
   "metadata": {},
   "source": [
    "## 3. Ingest (Bronze Layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cb9696",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sales_bronze = pd.read_csv(raw_dir/\"sales_raw.csv\", parse_dates=[\"date\"])\n",
    "inventory_bronze = pd.read_csv(raw_dir/\"inventory_raw.csv\", parse_dates=[\"snapshot_date\"])\n",
    "promo_bronze = pd.read_csv(raw_dir/\"promotions.csv\", parse_dates=[\"start_date\",\"end_date\"])\n",
    "customers_bronze = pd.read_csv(raw_dir/\"customers.csv\", parse_dates=[\"signup_date\"])\n",
    "\n",
    "# Save bronze copies\n",
    "sales_bronze.to_csv(bronze_dir/\"sales_bronze.csv\", index=False)\n",
    "inventory_bronze.to_csv(bronze_dir/\"inventory_bronze.csv\", index=False)\n",
    "promo_bronze.to_csv(bronze_dir/\"promo_bronze.csv\", index=False)\n",
    "customers_bronze.to_csv(bronze_dir/\"customers_bronze.csv\", index=False)\n",
    "\n",
    "sales_bronze.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38786efe",
   "metadata": {},
   "source": [
    "## 4. Transform (Silver Layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f9f63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sales_silver = sales_bronze.copy()\n",
    "sales_silver[\"revenue\"] = sales_silver[\"qty\"] * sales_silver[\"unit_price\"]\n",
    "sales_silver = sales_silver[sales_silver[\"qty\"] >= 0]\n",
    "\n",
    "sales_silver.to_csv(silver_dir/\"sales_silver.csv\", index=False)\n",
    "inventory_bronze.to_csv(silver_dir/\"inventory_silver.csv\", index=False)\n",
    "promo_bronze.to_csv(silver_dir/\"promo_silver.csv\", index=False)\n",
    "\n",
    "sales_silver.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08cb4ea3",
   "metadata": {},
   "source": [
    "## 5. Aggregate (Gold Layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947304d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gold_sales = sales_silver.groupby([\"date\",\"store_id\",\"sku\"], as_index=False).agg(\n",
    "    qty=(\"qty\",\"sum\"), revenue=(\"revenue\",\"sum\"), promo_count=(\"promo\",\"sum\")\n",
    ")\n",
    "gold_sales = gold_sales.merge(inventory_bronze, left_on=[\"date\",\"store_id\",\"sku\"],\n",
    "                              right_on=[\"snapshot_date\",\"store_id\",\"sku\"], how=\"left\")\n",
    "gold_sales.drop(columns=[\"snapshot_date\"], inplace=True)\n",
    "gold_sales[\"on_hand\"].fillna(gold_sales[\"on_hand\"].median(), inplace=True)\n",
    "gold_sales.to_csv(gold_dir/\"daily_sales_gold.csv\", index=False)\n",
    "\n",
    "gold_sales.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03686e7",
   "metadata": {},
   "source": [
    "## 6. Modeling (Demand Forecasting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d1a508",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = gold_sales.copy().sort_values([\"store_id\",\"sku\",\"date\"])\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "lag_days = 7\n",
    "for lag in range(1, lag_days+1):\n",
    "    df[f\"lag_{lag}\"] = df.groupby([\"store_id\",\"sku\"])[\"qty\"].shift(lag)\n",
    "df[\"dayofweek\"] = df[\"date\"].dt.weekday\n",
    "df[\"month\"] = df[\"date\"].dt.month\n",
    "df_model = df.dropna()\n",
    "\n",
    "features = [f\"lag_{i}\" for i in range(1, lag_days+1)] + [\"dayofweek\",\"month\",\"on_hand\",\"promo_count\"]\n",
    "target = \"qty\"\n",
    "\n",
    "cutoff_date = df_model[\"date\"].max() - timedelta(days=28)\n",
    "train = df_model[df_model[\"date\"] <= cutoff_date]\n",
    "test = df_model[df_model[\"date\"] > cutoff_date]\n",
    "\n",
    "X_train, y_train = train[features], train[target]\n",
    "X_test, y_test = test[features], test[target]\n",
    "\n",
    "model = GradientBoostingRegressor(n_estimators=200, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"MAPE:\", mean_absolute_percentage_error(y_test, y_pred))\n",
    "print(\"RMSE:\", mean_squared_error(y_test, y_pred, squared=False))\n",
    "\n",
    "joblib.dump(model, base/\"demand_model.joblib\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ca894a",
   "metadata": {},
   "source": [
    "## 7. Forecasting Next 7 Days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfdcdde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "last_date = gold_sales[\"date\"].max()\n",
    "future_dates = [pd.to_datetime(last_date) + timedelta(days=i) for i in range(1,8)]\n",
    "forecast_rows = []\n",
    "\n",
    "for store in gold_sales[\"store_id\"].unique():\n",
    "    for sku in gold_sales[\"sku\"].unique():\n",
    "        hist = gold_sales[(gold_sales.store_id==store)&(gold_sales.sku==sku)].sort_values(\"date\")\n",
    "        if hist.empty: continue\n",
    "        recent = hist.tail(lag_days)\n",
    "        lag_vals = list(recent[\"qty\"].values)[-lag_days:][::-1]\n",
    "        on_hand = recent[\"on_hand\"].iloc[-1]\n",
    "        for fd in future_dates:\n",
    "            feat = {f\"lag_{i}\": lag_vals[i-1] for i in range(1,lag_days+1)}\n",
    "            feat.update({\"dayofweek\": fd.weekday(), \"month\": fd.month, \"on_hand\": on_hand, \"promo_count\":0})\n",
    "            pred = model.predict(pd.DataFrame([feat]))[0]\n",
    "            pred_qty = max(0, int(round(pred)))\n",
    "            forecast_rows.append([fd.strftime(\"%Y-%m-%d\"), store, sku, pred_qty])\n",
    "            lag_vals = [pred_qty] + lag_vals[:-1]\n",
    "            on_hand = max(0, on_hand - pred_qty)\n",
    "\n",
    "forecast_df = pd.DataFrame(forecast_rows, columns=[\"date\",\"store_id\",\"sku\",\"forecast_qty\"])\n",
    "forecast_df.to_csv(gold_dir/\"forecast_daily.csv\", index=False)\n",
    "forecast_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253f3ee9",
   "metadata": {},
   "source": [
    "## 8. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95b2285",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sel_store, sel_sku = \"store_A\", \"sku_1\"\n",
    "hist_plot = gold_sales[(gold_sales.store_id==sel_store)&(gold_sales.sku==sel_sku)].sort_values(\"date\")\n",
    "last_60 = hist_plot.tail(60)\n",
    "future_plot = forecast_df[(forecast_df.store_id==sel_store)&(forecast_df.sku==sel_sku)]\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(pd.to_datetime(last_60[\"date\"]), last_60[\"qty\"], label=\"historical_qty\")\n",
    "plt.plot(pd.to_datetime(future_plot[\"date\"]), future_plot[\"forecast_qty\"], label=\"forecast_qty\", linestyle=\"--\")\n",
    "plt.xlabel(\"date\"); plt.ylabel(\"quantity\")\n",
    "plt.title(f\"Historical vs Forecast ({sel_store}/{sel_sku})\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4b6ae3",
   "metadata": {},
   "source": [
    "## 9. Outputs for Power BI\n",
    "- `gold/daily_sales_gold.csv`: Daily aggregated sales (for dashboards)\n",
    "- `gold/forecast_daily.csv`: Forecasts for next 7 days\n",
    "\n",
    "These CSVs can be imported directly into **Power BI** for building dashboards."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
